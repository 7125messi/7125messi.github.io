<!DOCTYPE html>
<!--[if lt IE 7]> <html class="no-js lt-ie9 lt-ie8 lt-ie7"> <![endif]-->
<!--[if IE 7]> <html class="no-js lt-ie9 lt-ie8"> <![endif]-->
<!--[if IE 8]> <html class="no-js lt-ie9"> <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js"> <!--<![endif]-->
<head>
  <meta http-equiv="content-type" content="text/html; charset=utf-8">
  <title>语言表征学习的思想演进  &middot; 7125messi的博客</title>
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1">


<meta name="description" content="" />

<meta name="keywords" content="">


<meta property="og:title" content="语言表征学习的思想演进  &middot; 7125messi的博客 ">
<meta property="og:site_name" content="7125messi的博客"/>
<meta property="og:url" content="https://7125messi.github.io/post/%E8%AF%AD%E8%A8%80%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E6%83%B3%E6%BC%94%E8%BF%9B/" />
<meta property="og:locale" content="zh-cn">


<meta property="og:type" content="article" />
<meta property="og:description" content=""/>
<meta property="og:article:published_time" content="2019-06-30T09:09:10&#43;08:00" />
<meta property="og:article:modified_time" content="2019-06-30T09:09:10&#43;08:00" />

  

  
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@" />
<meta name="twitter:creator" content="@" />
<meta name="twitter:title" content="语言表征学习的思想演进" />
<meta name="twitter:description" content="" />
<meta name="twitter:url" content="https://7125messi.github.io/post/%E8%AF%AD%E8%A8%80%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E6%83%B3%E6%BC%94%E8%BF%9B/" />
<meta name="twitter:domain" content="https://7125messi.github.io">
  

<script type="application/ld+json">
  {
    "@context": "http://schema.org",
    "@type": "Article",
    "headline": "语言表征学习的思想演进",
    "author": {
      "@type": "Person",
      "name": ""
    },
    "datePublished": "2019-06-30",
    "description": "",
    "wordCount":  1111 
  }
</script>



<link rel="canonical" href="https://7125messi.github.io/post/%E8%AF%AD%E8%A8%80%E8%A1%A8%E5%BE%81%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%80%9D%E6%83%B3%E6%BC%94%E8%BF%9B/" />

<link rel="apple-touch-icon-precomposed" sizes="144x144" href="https://7125messi.github.io/touch-icon-144-precomposed.png">
<link href="https://7125messi.github.io/favicon.png" rel="icon">

<meta name="generator" content="Hugo 0.55.6" />

  <!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
<script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
<![endif]-->

<link href='https://fonts.googleapis.com/css?family=Merriweather:300%7CRaleway%7COpen+Sans' rel='stylesheet' type='text/css'>
<link rel="stylesheet" href="/css/font-awesome.min.css">
<link rel="stylesheet" href="/css/style.css">
<link rel="stylesheet" href="/css/highlight/default.css">

  
  
</head>
<body>
  <main id="main-wrapper" class="container main_wrapper has-sidebar">
    <header id="main-header" class="container main_header">
  <div class="container brand">
  <div class="container title h1-like">
  <a class="baselink" href="https://7125messi.github.io">
  箴言

</a>

</div>

  
<div class="container topline">
  
  带着爱和梦想去生活


</div>


</div>

  <nav class="container nav primary no-print">
  

<a class="homelink" href="https://7125messi.github.io">正文</a>


  
<a href="https://7125messi.github.io/about">相关</a>

<a href="https://7125messi.github.io/post" title="Show list of posts">目录</a>


</nav>

<div class="container nav secondary no-print">
  


<a id="contact-link-github" class="contact_link" rel="me" aria-label="Github" href="https://github.com/7125messi">
  <span class="fa fa-github-square"></span></a>




 


















</div>


  

</header>


<article id="main-content" class="container main_content single">
  <header class="container hat">
  <h1>语言表征学习的思想演进
</h1>

  <div class="metas">
<time datetime="2019-06-30">30 Jun, 2019</time>


  
  &middot; Read in about 6 min
  &middot; (1111 Words)
  <br>
  


</div>

</header>

  <div class="container content">
  

<p>[参考整理]</p>

<p>参考文章：<a href="https://www.jiqizhixin.com/articles/2019-06-29-3">https://www.jiqizhixin.com/articles/2019-06-29-3</a></p>

<p>**在预训练语言模型 BERT 对自然语言处理的冲击还未平息时，CMU 和 Google 的研究员又放出了一个猛料：在 20 多项任务上全线碾压 BERT 的 XLNet。：由于在公众号中插入方式不方便，对于一个符号 &ldquo;a{b}^{c}&ldquo;，&rdquo;{b}&rdquo; 代表下标，&rdquo;{c}&rdquo; 代表上标。</p>

<p><a name="Hp76v"></a></p>

<h1 id="1-语言表征学习">1. 语言表征学习</h1>

<p>深度学习的基本单元是向量。我们将建模对象对应到各自的向量 x (或者一组向量 x{1}, x{2}, &hellip;, x{n})，然后通过变换、整合得到新的向量 h，再基于向量 h 得到输出的判断 y。这里的 h 就是我们说的<strong>表征 (Representation)</strong>，它是一个向量，描述了我们的建模对象。而<strong>语言</strong><a href="https://mp.weixin.qq.com/s/itNtDuQS4KF_sLnfiwdyNg"><strong>表征学习</strong></a>就是解决<strong>怎么样将一个词、一句话、一篇文章通过</strong><strong>变换 (Transformation)</strong><strong> 和</strong><strong>整合 (Aggregation) </strong><strong>转化成对应的向量 h 的问题。</strong></p>

<p>深度学习解决这个问题的办法是<strong>人工设计一个带有可调参数的模型，通过指定一系列的 (输入→输出) 对 (x → y)，让模型学习得到最优的参数</strong>。当参数确定之后，<strong>模型除了可以完成从 x 预测 y 的任务之外，其中间</strong><strong>把 x 变换成 h 的方法也是可以用到其他任务的。这也是我们为什么要做表征学习</strong><strong>。（就是说我们在做预测任务同时，顺便把表征学习这件事情给做了）</strong></p>

<p>所以我们要解决的问题便是：</p>

<ul>
<li>怎么确定 (输入→输出) 对，即模型的预测任务<br /></li>
<li>这个模型怎么设计<br /></li>
</ul>

<p><a name="Arfro"></a></p>

<h1 id="2-分布式语义假设"><strong>2. 分布式语义假设</strong></h1>

<p>任何任务都可以用来做表征学习：<strong>情感分析 (输入句子，判断句子是正向情感还是负向情感)，机器翻译 (输入中文，输出英文)。</strong>但是这些任务的缺点是<strong>需要大量的人工标注，这些标注耗时耗力。</strong>当标注量不够时，模型很<strong>容易学出&rdquo;三长一短选最短&rdquo;的取巧方案</strong> &ndash; 但我们想要的是真正的语言理解。</p>

<p>所幸语言学的研究中有一个重要的假设 &ndash; <strong>分布式语义假设 (Distributional Hypothesis)：</strong><br /></p>

<blockquote>
<p>One shall know a word by the company it keeps.[1]
我们可以通过一个词出现的语境知道这个词的意思。</p>
</blockquote>

<p><br />所以我们可以将输入 x 定为目标词的<strong>语境</strong>，输出 y 定为<strong>目标词</strong>。这个任务的优点是<strong>我们并不需要人工标注的数据，只需要许多有意义的语段就可以了</strong> &ndash; 而在信息爆炸的互联网时代，这种数据是取之不尽的。</p>

<p>_如何更精细地建模<strong>语境</strong>，得到其对应的表征向量 h？对这个问题的解答贯穿了语言表征学习的发展历程_。我们希望能够做到：</p>

<ol>
<li><p><strong>语境要包含所有区分目标词的信息。</strong>只有这样才不会有歧义的出现，比如给定语境 [&ldquo;我&rdquo; &ldquo;今天&rdquo; &ldquo;很&rdquo;]，目标词 (下一个词) 既可以是 &ldquo;开心&rdquo;，也可以是&rdquo;伤心&rdquo;，所以模型学不到 &ldquo;开心&rdquo; 和 &ldquo;伤心&rdquo; 的区别。语境要足够大，如对于一篇文章中的一个目标词，<strong>理想的语境是文章中除了目标词的所有词。</strong></p></li>

<li><p><strong>建模语境中词的相互依赖关系。</strong>除了词本身的性质外 (这决定了词的依赖关系，比如形容词可以修饰名词短语，猫一般不会用巍峨来修饰)，<strong>在大部分语言 (如中文，英文) 中，词的相对位置也决定了词间的依赖关系。</strong><br /></p></li>
</ol>

<p>下文开始我们会围绕这个句子展开讨论：</p>

<p>[&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, “开心4”, “&lt;逗号&gt;5”, “因为6”, “我7”, “中8”, “了9”, “彩票10”]</p>

<p>数字代表词在句子中的位置编号。「我 1」和「我 7」虽然是同一个词，但因为出现在句子的不同位置，所以他们表达的意思可能不同。假设我们的目标词是「开心 4」，语境中便不应该含有「开心 4」，因为这会造成标签泄露 &ndash; 我们在提出问题的同时也直白地给出了答案 <strong>&ndash; 此时模型很难学出有用的语言知识。所以理想的语境建模应基</strong><strong>于[&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, “&lt;逗号&gt;5”, “因为6”, “我7”, “中8”, “了9”, “彩票10”] 以及位置 &rdquo;4&rdquo;。</strong><br />**
<a name="wbyWb"></a></p>

<h1 id="br-3-预训练词向量-word-embedding"><br />3. 预训练词向量 (Word Embedding)</h1>

<p>神经网络刚开始进入自然语言处理的时候，<strong>预训练词向量 (Word Embedding</strong>) 的方法如 Skip-gram, Glove 等是语言表征学习的主要手段。由于缺乏有效建模词的相互依赖的手段，我们<strong>使用目标词前后的窗口内的词作为目标词的语境词 (Context Word)，每个词/语境词都有一个独立的向量作为其表征。</strong></p>

<p>假如窗口长度是 2 的话，在上述例子中，我们可以得到的 (输入→输出) 对为 (&ldquo;很&rdquo; → &ldquo;开心&rdquo;)，(&rdquo;&lt;逗号&gt;&ldquo;→ &ldquo;开心&rdquo;)，(&ldquo;今天&rdquo; → &ldquo;开心&rdquo;)，(&ldquo;因为&rdquo; → &ldquo;开心&rdquo;)。这里<strong>为了避免统计稀疏性，我们丢弃了词的位置信息。</strong></p>

<p><strong>这种语境建模方式非常粗糙。滑动窗口只是词间相互依赖的一种粗略</strong><strong>估计</strong>。同时<strong>单个语境词不足以表达丰富的语境信息 &ndash; 这是由语境中不同词相互依赖共同决定的。</strong>这使得该预测任务存在大量的歧义。最后由于缺乏对语境的细致建模，我们只能学到单个词的模糊的表征。</p>

<p><a name="AjjNu"></a></p>

<h1 id="4-循环神经网络">4. 循环神经网络</h1>

<p><strong><br />用一个向量代表一个词在_</strong>预训练词向量流行之后已经变成标准做法<strong>_，也是我们用上神经网络模型组件的基础。我们的</strong>句子可以表示成一个有顺序的向量序列:**<br /></p>

<blockquote>
<p>[x{我}, x{今天}, x{很}, x{开心}, x{&lt;逗号&gt;}, x{因为}, x{我}, x{中}, x{了}, x{彩票}]</p>
</blockquote>

<p><br />为了从这个向量序列计算出对应的表征向量 h，我们必须<strong>对这个向量序列进行变换 (Transformation) 和整合 (Aggregation)。</strong>循环神经网络 (Recurrent Neural Network, RNN) <strong>通过一个递归算子实现了这个目的</strong>：</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429336-9f1a4f69-a0f3-4b85-91f4-5aeb36607654.webp#align=left&amp;display=inline&amp;height=61&amp;originHeight=34&amp;originWidth=362&amp;size=0&amp;status=done&amp;width=646" alt="" /><br />
<br />我们按照一个顺序 (从左到右) 对上述向量序列编号: </p>

<p>[x{1}, x{2}, x{3}, x{4}, x{5}, x{6}, x{7}, x{8}, x{9}, x{10}]</p>

<p><br /><strong>按照编号的顺序</strong>，在第 t 位时，循环神经网络会<strong>根据第 t-1 位的表征 h{t-1} 及当前的输入 x{t} 算出当前位置的表征 h{t}</strong> <br />&ndash; 这便是序列 [x{1}, x{2}, &hellip;, x{t}] 对应的表征。可以看到<strong>输入向量的相对位置决定了循环神经网络整合信息的计算顺序</strong>，或者说<strong>相对位置决定了计算图 (Computation Graph) 的构建。</strong></p>

<p><a name="OKIDf"></a></p>

<h1 id="5-自回归语言模型">5. 自回归语言模型 </h1>

<p><strong><br />在拥有循环神经网络这一序列建模利器之后，我们可以对语境进行更精细的建模。由于 RNN 的运算模式是按顺序依次处理每个词，所以语境可以是</strong>目标词前面的所有词**<strong>。</strong></p>

<p>对于例子 [&ldquo;我 1&rdquo;, &ldquo;今天 2&rdquo;, &ldquo;很 3&rdquo;,&ldquo;开心 4&rdquo;,&rdquo;&lt;逗号&gt;5&rdquo;,&ldquo;因为 6&rdquo;,&ldquo;我 7&rdquo;,&ldquo;中 8&rdquo;,&ldquo;了 9&rdquo;,彩票 10&rdquo;]，如果编号顺序是从左到右的话，对应的输入-输出对为 ([&ldquo;我&rdquo;, &ldquo;今天&rdquo;, &ldquo;很&rdquo;] → &ldquo;开心&rdquo;)；而从右到左则对应的是 ([&ldquo;彩票&rdquo;, &ldquo;了&rdquo;, &ldquo;中&rdquo;, &ldquo;我&rdquo;, &ldquo;因为&rdquo;, &ldquo;&lt;逗号&gt;&ldquo;] → &ldquo;开心&rdquo;)。因为<strong>目标词总是语境的下一个词</strong>，所以我们<strong>并不需要输入目标词的位置信息</strong>。如前所述，<strong>词的相对位置决定了词的输入顺序，所以词的位置也不再需要输入了。</strong></p>

<p><strong>自回归语言模型的优点是计算效率比较高。</strong>我们只要对[&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, “开心4”, “&lt;逗号&gt;5”, “因为6”, “我7”, “中8”, “了9”, “彩票10”] 这句话做一次表征计算，便可以得到许多输入输出对的语境表征：([&ldquo;我&rdquo;] → &ldquo;今天&rdquo;)，([&ldquo;我&rdquo;, &ldquo;今天&rdquo;]→ &ldquo;很&rdquo;)，([&ldquo;我&rdquo;, &ldquo;今天&rdquo;, &ldquo;很&rdquo;] → &ldquo;开心&rdquo;) 等等。</p>

<p><em><strong>自回归语言模型也是自然语言生成的标准方案</strong></em> <br />&ndash; 一个句子的生成可以转化成以前面的片段为语境，预测下一个词的任务。<br />而<strong>新预测的词可以拼到已经生成的片段，作为预测下一个词所依据的语境。</strong></p>

<p>由于<strong>可以对语境进行建模</strong>，预训练词表征便可以从语境无关的词向量变成<strong>基于语境的词表征 (Contextual Representation)</strong>。再结合增大数据量带来的巨大增益，这也使得 2018 年发表的 ELMo 成为自然语言处理领域第一个刷榜的大新闻。</p>

<p>但<strong>这种语境建模方式只使用了目标词左边 (右边) 单方向的所有词，所以预测任务仍然会存在歧义</strong>。语料中输入输出对 ([&ldquo;我&rdquo;, &ldquo;今天&rdquo;, &ldquo;很&rdquo;] → &ldquo;开心&rdquo;) 和 ([&ldquo;我&rdquo;, &ldquo;今天&rdquo;, &ldquo;很&rdquo;] → &ldquo;伤心&rdquo;) 都有可能出现，所以模型学不到 &ldquo;开心&rdquo; 和 &ldquo;伤心&rdquo; 的区别。</p>

<p>如何将目标词左右的语境 (双向语境) 同时引入建模便成为下一个需要解决的问题。一个简单的做法是<strong>分别学一个前向及后向的自回归语言模型</strong>，然后<strong>再将两个模型学出的表征合并。这便是 ELMo 里的标准做法。</strong>然而这种独立建模虽然拿到了两个方向的语境信息，但却<strong>学不出两个语境间细致的依赖关系</strong>。</p>

<p><a name="CwaO2"></a></p>

<h1 id="6-transformer">6. Transformer</h1>

<p><strong>双向语境的建模困难主要源于循环神经网络单向、顺序的计算方式。</strong>除了限制依赖关系的方向之外，这种计算方式也<strong>限制了</strong><strong>循环</strong><strong>神经网络能建模的最大依赖距离</strong>。x{1} 和 x{300} 的间依赖关系需要通过重复计算 300 次 <img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429342-e813e71b-50c0-4aa5-bef9-b2e336f62bc0.webp#align=left&amp;display=inline&amp;height=28&amp;originHeight=34&amp;originWidth=168&amp;size=0&amp;status=done&amp;width=140" alt="" />才能求得。而由于循环神经网络中存在矩阵乘法，在计算 x{300} 时 x{1} 的信息被相同的矩阵乘了 300 次。视矩阵 W{h} 的模不同，会导致信息的爆炸 (|W{h}|&gt;1) 或者消失 (|W{h}|&lt;1)。</p>

<p><strong>我们既要取得双向依赖建模，又要让长距离的依赖中间间隔的计算操作尽可能的少。</strong>Transformer 的提出实现了这两个目的。细节如**层归一化 (Layer Normalization)，多注意力算子 (Multi-Head Attention) <strong>可以参考原论文，这里主要介绍最核心的</strong>自注意力算子 (Self-Attention)，及其基础 &ndash; 注意力算子 (Attention)。**</p>

<p>我们先介绍<strong>注意力算子 (Attention)</strong>。注意力算子的基本元素为<strong>查询向量 (Query Vector) q{i}，地址向量 (Key Vector) k{j} 以及内容向量 (Value Vector) v{j}</strong>。其输出 h{i} 为所有内容向量的<strong>加权求和</strong>，每个权重由查询向量和地址向量算出的<strong>注意力权重</strong> (Attention Score) 决定:</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429332-8f2cecd0-7e26-44bf-a464-9b6fdf7cdf7b.webp#align=left&amp;display=inline&amp;height=95&amp;originHeight=64&amp;originWidth=500&amp;size=0&amp;status=done&amp;width=746" alt="" /><br />
<br /><strong>注意力算子</strong>达到的目的是<strong>基于查询向量对一组表征信息进行聚合。</strong></p>

<p>回到建模依赖关系的问题上。既然每个词都可能对其他词产生依赖，那我们让每个词都用注意力算子从其他词那里聚合信息不就好了嘛！这便是<strong>自注意力 (Self-Attention) 的动机。</strong></p>

<p>对于第 i 个词，我们可以<strong>根据其词向量 x{i} 算出其对应的查询向量、地址向量以及内容向量</strong>：</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429338-595ba78f-aabf-48fa-846d-20346e9e7018.webp#align=left&amp;display=inline&amp;height=86&amp;originHeight=36&amp;originWidth=254&amp;size=0&amp;status=done&amp;width=606" alt="" /><br />
<br />在进行表征聚合时，<strong>q 来自要求表征的词</strong>，<strong>k 和 v 来自所有词 (包括要求表征的词本身)</strong>。&rdquo;<strong>自注意力 (Self-Attention)&rdquo; 中之所以有 &ldquo;自 (Self)&ldquo;，是因为查询、地址和内容的角色均来自同一个序列。</strong></p>

<p>自注意力算子的引入解决了循环神经网络的两个问题：第 i 个词表征 h{i} 的构建可以同时基于双向的语境；词间不管依赖距离多长，都只间隔了一次运算操作。</p>

<p>但是自注意力算子会引入新的问题 <strong>&ndash; 词的相对位置的信息被丢弃了</strong>。回到我们的例句[&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, “开心4”, “&lt;逗号&gt;5”, “因为6”, “我7”, “中8”, “了9”, “彩票10”]，丢弃词的相对位置意味着在自注意力算子眼里，&rdquo;我 1&rdquo; 和「我 7」表达的意思是一样的。解决这个问题的方法是<strong>将位置作为词表征的一部分一并输入模型。</strong>Transformer 采用的是简单粗暴的加法：&rdquo;我 1&rdquo; 和「我 7」的表征分别为</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429335-020967bf-99f2-43eb-88e4-fb00eb6ce293.webp#align=left&amp;display=inline&amp;height=146&amp;originHeight=86&amp;originWidth=154&amp;size=0&amp;status=done&amp;width=261" alt="" /><br />
<br /><strong>其中 p1 和 p7 是位置 1 和 7 对应的位置编码 (Position Embedding)</strong>。这和循环神经网络截然不同：</p>

<ul>
<li><p>在循环神经网络里，<strong>相对位置决定了计算的顺序；</strong></p></li>

<li><p><strong>在 Transformer 里则是决定了词的表征。</strong></p></li>
</ul>

<p>在后文会提到，将<strong>位置纳入词表征的做法在 XLNet 中被巧妙地利用了。</strong></p>

<p><strong>Transformer 在每个词基于语境的表征时会同时用上前后语境，但是自回归语言模型却限制了语境的方向。</strong>鉴于自回归语言模型在自然语言生成中的普遍应用，为了使用灵活的 Transformer 进行建模，我们需要对 Transformer 进行相应的修改。**解决方案是对计算出的注意力权重进行屏蔽 **</p>

<ul>
<li>&ndash; 我们强行将不想要的注意力权重置为 0，这样计算表征的时候就不会用到目标词及其右边的词了</li>
<li>&ndash; 这些词的注意力权重为 0。这称之为<strong>注意力掩码 (Attention Mask)。</strong>这一点也是构建 XLNet 训练目标所必须的技巧。再加上对下游任务的适配以及大量的数据，GPT 和 GPT-2 也搞了一波大新闻。</li>
</ul>

<p>上述构造技巧再加上<strong>多注意力算子 (Multi-Head Attention)</strong> 以及<strong>标准深度学习组件的组合 (Dropout, Position-Wise FeedForwrd Layer, Layer Normalization)，Transformer 给自然语言处理的建模方式带来了变革性的贡献，无愧其名 &ldquo;Transformer&rdquo;(改革者)。</strong></p>

<p><a name="7Dbmz"></a></p>

<h1 id="7-去噪自编码模型-掩码语言模型">7. 去噪自编码模型/掩码语言模型 </h1>

<p> <br /><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429346-f413bce3-ec61-4d3a-b4a3-88817eda1e56.webp#align=left&amp;display=inline&amp;height=487&amp;originHeight=570&amp;originWidth=874&amp;size=0&amp;status=done&amp;width=746" alt="" /><br />
<br />加入 Transformer 后，我们的军火库多了<strong>建模双向语境的武器。</strong>但是如前所述，<strong>自注意力算子构建的是第 i 个词基于语境的表征，使用这个表征来预测第 i 个词会带来标签泄露</strong>。这就好比在给你出题的时候顺便直白地告诉了你答案。</p>

<p>我们既想<strong>用上 Transformer 的建模能力，又想从第 i 个词的表征中剔除这个词的信息。</strong>以 BERT 为代表的**去噪自编码模型 (Denoising Auto-Encoder)/掩码语言模型 (Masked Language Modeling) <strong>的做法是将这些词替换成特殊字符 &ldquo;MASK&rdquo;。&rdquo;MASK&rdquo; 对应的表征即为原来词的语境表征，既获得了双向语境的信息，又避免了标签泄露，可以用来预测原来的词。为了复用计算出的表征，BERT 会随机选取多个词替换成 &ldquo;MASK&rdquo;，然后在对应的位置分别预测原来的词。由于这些词都被替换成相同的字符 &ldquo;MASK&rdquo;，他们对应的语境表征计算的区别主要来</strong>自于其位置编码。**</p>

<p>对于本文开头的例子，我们构建的 (输入→输出) 对为 ([&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, <strong>“MASK4”</strong>,“&lt;逗号&gt;5”,“因为6”,“我7”,“中8”,“了9”,“彩票10”]→ 开心)。</p>

<p>虽然结合 Transformer 和去噪自编码模型的 BERT 可以说是拿到了语境建模的&rdquo;双向圣杯&rdquo;，其设计的次句判断任务 (Next sentence prediction) 也对下游任务有重要帮助。但是人无完人，BERT 无完 BERT。**BERT 中 &ldquo;MASK&rdquo; 字符的加入，使得非目标词表征的建模都会依赖于人造的 &ldquo;MASK&rdquo; 字符，这会使模型学出虚假的依赖关系 (比如 &ldquo;MASK&rdquo; 可以作为不同词信息交换的桥梁) **&ndash; 但 &ldquo;MASK&rdquo; 在下游任务中并不会出现。这便是 <strong>XLNet 中提到的预训练-微调差异 (Pretrain-Finetune Discrepancy)</strong>。同时除了**位置编码 p **的区别外，同一句话内所有目标词依赖的语境信息完全相同，这除了忽略被替换的词间的依赖关系外，随着网络层数的加深，作为输入的位置编码 p 的信息也可能被过多的计算操作抹去 (类似于上述循环神经网络难以建模长程依赖的原因)。</p>

<p><a name="FPkMA"></a></p>

<h1 id="8-xlnet-的核心贡献-乱序语言模型">8. XLNet 的核心贡献: 乱序语言模型</h1>

<p>如上所述，</p>

<ul>
<li><strong>BERT 虽然充分地建模了双向语境信息</strong>，但是其用来<strong>预测不同目标词的语境信息只有目标位置编码的区别，同时也建模不了被替换成 &ldquo;MASK&rdquo; 的词间的依赖关系。</strong></li>
<li><strong>自回归语言模型虽然只能建模单向的语境，但是其计算效率比较高，且预测每个词所用的语境都是不一样的。怎么把这两者的长处结合呢？</strong></li>
</ul>

<p>回顾我们对自回归语言模型的介绍。对于一句话[&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, “开心4”, “&lt;逗号&gt;5”, “因为6”, “我7”, “中8”, “了9”, “彩票10”]，我们得到的输入输出样本为([&ldquo;我&rdquo;] → &ldquo;今天&rdquo;)，([&ldquo;我&rdquo;, &ldquo;今天&rdquo;]→ &ldquo;很&rdquo;)，([&ldquo;我&rdquo;, &ldquo;今天&rdquo;, &ldquo;很&rdquo;] → &ldquo;开心&rdquo;)&hellip;等等。这些样本中的语境毫无例外都是单向且有序的。</p>

<p>对样本语境的选取是否可以更灵活一些？在上述对分布式语义假设的介绍中我们提到，语境中的词之间的相互依赖关系，一是取决于词本身的性质，二是取决于语境中词的相对位置。所以有了词以及词在语境中的位置，我们就有了从这个词构建依赖关系的全部信息。所以对于同一句话 [&ldquo;我 1&rdquo;, &ldquo;今天 2&rdquo;, &ldquo;很 3&rdquo;,「开心 4」,「&lt;逗号&gt;5」,「因为 6」,「我 7」,「中 8」,「了 9」,「彩票 10」]，我们可以使用更灵活的样本选取办法，得到([&ldquo;我1&rdquo;] → “开心4”)，([“我1”, “开心4”] → ”今天2“)，([”我1“, ”今天2“, “开心4”] → “很3”)&hellip;等等。这便是乱序语言模型 (Permutation Language Modeling) 的思想。和自回归语言模型不一样，新的样本中的语境需要输入词的位置，否则就退化成了词带模型 (Bag of Words)。这可以类比到人的阅读方式：字词在书本上的位置是一定的，但从左到右的阅读顺序并不是强制的，我们还可以跳读。<br />
<br />从概率模型的角度考虑，上述对样本的采样方式的不同对应了对句子概率 P(&ldquo;我1&rdquo;, &ldquo;今天2&rdquo;, &ldquo;很3&rdquo;, “开心4”, “&lt;逗号&gt;5”, “因为6”, “我7”, “中8”, “了9”, “彩票10”) 的不同分解。<br />
<br />对于自回归语言模型，其分解方式为P(&ldquo;我 1&rdquo;)P(&ldquo;今天 2&rdquo; |&ldquo;我 1&rdquo;)P(&ldquo;很 3&rdquo;|&ldquo;我 1&rdquo;, &ldquo;今天 2&rdquo;)P(&ldquo;开心 4&rdquo;|&ldquo;我 1&rdquo;, &ldquo;今天 2&rdquo;, &ldquo;很 3&rdquo;)&hellip;</p>

<p>对于乱序语言模型，其分解方式可以为P(&ldquo;我 1&rdquo;)P(&ldquo;开心 4&rdquo;|&ldquo;我 1&rdquo;)P(&ldquo;今天 2&rdquo;|&ldquo;我 1&rdquo;,&ldquo;开心 4&rdquo;)P(&ldquo;很 3&rdquo;|&ldquo;我 1&rdquo;,&ldquo;今天 2&rdquo;,&ldquo;开心 4&rdquo;)&hellip;</p>

<p>每一种分解方式由一个随机排列 z 确定，如上述分解方式对应 z = [z{1} ,z{2} , z{4} , z{3} , &hellip;] → [&ldquo;我 1&rdquo;→&rdquo;今天 2&rdquo;→&rdquo;开心 4&rdquo;→&rdquo;很 3&rdquo;→ &hellip;]</p>

<p>其中 z{t} 代表随机排列的第 t 个词。乱序语言模型是自回归语言模型的一种推广，因为 z 可以是原来序列的顺序。</p>

<p>乱序语言模型的语境可以同时来自目标词的前向和后向，所以其建模了双向的依赖。每个被预测的词 (除最后一个词外) 都会加入到语境中，所以既解决了 BERT 忽略被替换的词间的依赖关系的问题，又解决了 BERT 不同目标词依赖的语境趋同的问题。相比于 BERT 一次性输入几乎所有的语境信息，乱序语言模型可以认为是对双向语境进行了采样 (或者 Embedding Dropout)，这会产生类似于 Dropout 效果，可以让模型学出更鲁棒的语境依赖。</p>

<p>但需要注意的是，当构成语境的词比较少时，根据语境预测目标词的歧义性就会增大，训练难度也会增大。这也是为什么 XLNet 只采样了一小部分词去预测的原因。</p>

<p>讲了这么多好处，那如何用 Transformer 实现乱序语言模型呢？</p>

<p><a name="LuIEn"></a></p>

<h1 id="9-乱序语言模型的实现-双自注意力通道">9. 乱序语言模型的实现：双自注意力通道</h1>

<p><strong>Transformer 中每个词的表征由其词向量和位置编码共同决定</strong> &ndash; 我们既拿到了词本身的性质，又有词的位置信息。所以 Transformer 天然就和乱序语言模型相契合。</p>

<p>假设整句话为 [&ldquo;我 1&rdquo;, &ldquo;今天 2&rdquo;, &ldquo;很 3&rdquo;,「开心 4」]，我们只采样出一个样本 ([&ldquo;今天 2&rdquo;, &ldquo;很 3&rdquo;, &ldquo;开心 4&rdquo;] → &ldquo;我 1&rdquo; )，XLNet 的做法和 BERT 有同有异。</p>

<p>和 BERT 一样，XLNet 同样是将目标词 &ldquo;我 1&rdquo; 替换成一个特殊字符 &ldquo;MASK1&rdquo;。<br />和 BERT 不同，&rdquo;MASK&rdquo; <strong>不会纳入表征的地址向量 k 以及内容向量 v 的计算</strong>，&rdquo;MASK&rdquo; 自始至终<strong>只充当了查询向量 q 的角色</strong>，因此<strong>所有词的表征中都不会拿到 &ldquo;MASK&rdquo; 的信息</strong>。这也<strong>杜绝了 &ldquo;MASK&rdquo; 的引入带来的预训练-微调差异 (Pretrain-Finetune Discrepancy) &ndash; 这个改动也可以直接应用到 BERT 上面。</strong></p>

<p>在下图中记 <strong>&ldquo;MASK&rdquo; 对应的词向量为 G，X2 - X4 为各自的词向量</strong>，<strong>G1, H1 - H4 为各自的表征</strong>。图中省略了<strong>位置编码 p。</strong><br /> <br /><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429359-295ab878-1890-4541-987b-123319d638c0.webp#align=left&amp;display=inline&amp;height=661&amp;originHeight=775&amp;originWidth=874&amp;size=0&amp;status=done&amp;width=746" alt="" /></p>

<p>上面只是讨论最简单的情况 &ndash; 即一句话只产生一个样本。但我们还希望保证训练效率 &ndash;** 我们想和自回归语言模型一样，只进行一次整句的表征计算便可以获得所有样本的语境表征<strong>。这时所有词的表征就必须同时计算，此时便有标签泄露带来的矛盾：</strong>对于某个需要预测的目标词，我们既需要得到包含它信息以及位置的表征 h (用来进一步计算其他词的表征)，又需要得到不包含它信息，只包含它位置的表征 g (用来做语境的表征)。**</p>

<p>一个很自然的想法就是<strong>同时计算两套表征</strong>，这便是** XLNet 提出的双通道自注意力 (Two Stream Self-Attention)<strong>，同时计算内容_</strong>表征通道 (Content Stream) h 和语境表征通道 (Query Stream) g**_。注意这里采用的是意译而不是直译，请读者谅解。</p>

<p>假设我们要计算第 1 个词在第 l 层的语境表征 g{1}^{l} 和内容表征 h{1}^{l}，我们只关注注意力算子查询向量 Q、地址向量 K 以及内容向量 V 的来源：<br />
<br /><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429358-7ae1f45b-1551-45b4-94f4-94c0881071c5.webp#align=left&amp;display=inline&amp;height=189&amp;originHeight=82&amp;originWidth=324&amp;size=0&amp;status=done&amp;width=746" alt="" /><br />
<br />计算 g{1}^l 时用到了 h{j!=1}^{l-1}，表示第 l-1 层除了第 1 个词外所有词的表征，这是为了保证标签不泄露；计算 h{1}^{l} 时用到了 h{:}^{l-1}，表示第 l-1 层所有词的表征，这和标准的 Transformer 计算表征的过程一致。<br /> <br /><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429366-5a462305-d9a7-472c-8044-e9872251238a.webp#align=left&amp;display=inline&amp;height=520&amp;originHeight=616&amp;originWidth=874&amp;size=0&amp;status=done&amp;width=738" alt="" /><br />
<br />但上述做法在_<strong>堆叠多层自注意算子时仍然会带来标签泄露</strong>_。</p>

<p>虽然计算 g{1}^{l} 时我们已经采取措施防止 h{1}^{l-1} 的信息泄露到 g{1}^{l} 中，但是考虑两层自注意力算子的计算：</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429365-e516bc8e-46dc-4fd8-969f-33fee90cedc2.webp#align=left&amp;display=inline&amp;height=90&amp;originHeight=80&amp;originWidth=664&amp;size=0&amp;status=done&amp;width=746" alt="" /></p>

<p>我们看到第 l-2 层第 1 个词的表征 h{1}^{l-2} 会通过第 l-1 层的所有表征 h{j}^{l-1} 泄露给 g{1}^{l}。</p>

<p>和<strong><em>将 Transformer 应用到自回归语言模型的情况类似，我们还需要对每层的注意力使用注意力掩码 (Attention Mask)，根据选定的分解排列 z，将不合理的注意力权重置零。</em></strong>我们记 z{t} 为分解排列中的第 t 个词，那我们在词 z{t} 的表征时，g{t}^{l} 和 h{t}^{l} 分别只能看到排列中前 t-1 个词 z{1:t-1} 和前 t 个词 z{1:t}，即</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429374-1d0cbcdd-bb6d-4571-ad56-3d85df1ed12e.webp#align=left&amp;display=inline&amp;height=173&amp;originHeight=78&amp;originWidth=336&amp;size=0&amp;status=done&amp;width=746" alt="" /></p>

<p>在如此做完注意力掩码后，所有 g{z{t}}^l 便可以直接用来预测词 z{t}，而不会有标签泄露的问题。</p>

<p>这里我们也可以看到，<em><strong>在具体实现效率的限制下，想要获得多样的语境并防止标签泄露，我们只能依据乱序语言模型的定义去使用注意力掩码。这也体现了 XLNet 设计的精巧性。</strong></em></p>

<p><a name="c4R7t"></a></p>

<h1 id="10-xlnet-的重要元素-transformer-xl">10. XLNet 的重要元素：Transformer-XL</h1>

<p>**<br />上面已经提到，和循环神经网络不同，Transformer 是同时计算语段内所有词的表征的。受限于系统内存大小，Transformer 输入的序列长度会有一个上限。通常我们会将过长的序列切成固定长度为 N 的片段，再依次输入 Transformer 计算表征。所以 Transformer 的构造虽然降低了长程依赖的学习难度，但其最长只能建模长度为 N 的依赖。</p>

<p>为了在内存的限制下让 Transformer 学到更长的依赖，<strong>Transformer-XL 借鉴了 TBPTT(Truncated Back-Propagation Through Time) 的思路，将上一个片段 s{t-1} 计算出来的表征缓存在内存里，加入到当前片段 s{t} 的表征计算中。</strong><br /> <br /><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429372-40820c50-f565-40e1-a5ac-6c800ff81009.webp#align=left&amp;display=inline&amp;height=475&amp;originHeight=556&amp;originWidth=874&amp;size=0&amp;status=done&amp;width=746" alt="" /></p>

<p>如上图所示，由于计算第 l 层的表征时，使用的第 l-1 层的表征同时来自于片段 s{t} 和 s{t-1}，所以每增加一层，模型建模的依赖关系长度就能增加 N。在上图中，<em><strong>Transformer-XL 建模的最长依赖关系为 3*2=6。</strong></em></p>

<p>但这又会引入新的问题。_<strong>Transformer 的位置编码 (Position eEmbedding) 是绝对位置编码 (Absolute Position Embedding)</strong>_，即每个片段内，各个位置都有其独立的一个位置编码向量。所以片段 s{t} 第一个词和片段 s{t-1} 第一个词共享同样的位置编码 &ndash; 这会带来歧义。</p>

<p><strong>Transformer-XL 引入了更加优雅的相对位置编码 (Relative Position Embedding)。</strong></p>

<p>因为位置编码只在自注意力算子中起作用，我们_<strong>将 Transformer 的自注意力权重的计算拆解成</strong>_：</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429381-25d13cfd-e162-47ca-a593-59fb488f7cfb.webp#align=left&amp;display=inline&amp;height=57&amp;originHeight=44&amp;originWidth=574&amp;size=0&amp;status=done&amp;width=746" alt="" /><br />
<br />我们可以将其中的绝对位置编码 p{j} 的计算替换成相对位置编码 r{i-j}，把 p{i} 替换成一个固定的向量 (认为位置 i 是相对位置的原点)。这样便得到相对位置编码下的注意力权重：</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429381-88c6176a-de9d-470d-b497-c91345c62b9b.webp#align=left&amp;display=inline&amp;height=56&amp;originHeight=44&amp;originWidth=588&amp;size=0&amp;status=done&amp;width=746" alt="" /><br />
<br />Transformer-XL 的实际实现方式与上式有所不同，但思想是类似的。</p>

<p><strong><em>相对位置编码解决了不同片段间位置编码的歧义性。</em></strong>通过这种拆解，我们可以进一步<em><strong>将相对位置编码从词的表征中抽离，只在计算注意力权重的时候加入。这可以解决 Transformer 随着层数加深，输入的位置编码信息被过多的计算抹去的问题。Transformer-XL 在 XLNet 中的应用使得 XLNet 可以建模更长的依赖关系。</strong></em></p>

<p><a name="wHrMJ"></a></p>

<h1 id="11-xlnet-的模型改进增益">11. XLNet 的模型改进增益</h1>

<p>文章最后的消融分析很好地证明了_<strong>乱序语言模型和 Transformer-XL 主干网络带来的提升</strong>_。这部分实验采用和 BERT 一致的训练数据。以 BERT 为基础，将 BERT 的主干网络从 Transformer 换成 Transformer-XL 后，在需要建模较长上下文的阅读理解任务 RACE 和 SQuAD2.0 均有比较明显地提升 (对比 1&amp;2 行)。而在此基础上加上乱序语言模型后，在所有任务上都有不同程度的提升 (对比 2&amp;3 行)。<br /> <br /><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429387-8eb847d4-aabd-4714-8c63-e028f9050e4c.webp#align=left&amp;display=inline&amp;height=154&amp;originHeight=181&amp;originWidth=874&amp;size=0&amp;status=done&amp;width=746" alt="" /><br /></p>

<p><a name="6nNw6"></a></p>

<h1 id="12-如何评价-xlnet">12. 如何评价 XLNet</h1>

<p>自词向量到如今以 XLNet 为代表的预训练语言模型，他们的主要区别在于<strong>对语境的不同粒度的建模</strong>：</p>

<p><img src="https://cdn.nlark.com/yuque/0/2019/webp/200056/1561819429388-2b0f2781-f886-4d6d-ade0-f1d5d49b9666.webp#align=left&amp;display=inline&amp;height=216&amp;originHeight=312&amp;originWidth=1080&amp;size=0&amp;status=done&amp;width=746" alt="" /><br /></p>

<p>XLNet 的成功来自于三点：</p>

<ol>
<li>分布式语义假设的有效性，即我们确实可以<strong>从语料的统计规律中习得常识及语言的结构。</strong><br /></li>
<li>对语境更加精细的建模：<strong>从&rdquo;单向&rdquo;语境到&rdquo;双向&rdquo;语境，从&rdquo;短程&rdquo;依赖到&rdquo;长程&rdquo;依赖，XLNet 是目前对语境建模最精细的模型。</strong><br /></li>
<li>在模型容量足够大时，<em><strong>数据量的对数和性能提升在一定范围内接近正比 [3] [4]：XLNet 使用的预训练数据量可能是公开模型里面最大的。</strong></em><br /></li>
</ol>

<p>可以预见的是资源丰富的大厂可以闭着眼睛继续顺着第三点往前走，或许还能造出些大新闻出来，这也是深度学习给的承诺。这些大新闻的存在也渐渐堵住调参式的工作的未来，迫使研究者去思考更加底层，更加深刻的问题。</p>

<p>对语境的更精细建模自然是继续发展的道路，以语言模型为代表的预训练任务和下游任务之间的关系也亟待探讨。</p>

<p>退后一步讲，分布式语义假设的局限性在哪里？根据符号关联假设 (Symbol Interdependency Hypothesis)[5]，虽然语境的统计信息可以构建出符号之间的关系，从而确定其相对语义。但我们仍需要确定语言符号与现实世界的关系 (Language Grounding)，让我们的 AI 系统知道，&rdquo;红色&rdquo;对应的是红色，&rdquo;天空&rdquo;对应的是天空，&rdquo;国家&rdquo;对应的是国家。这种对应信息是通过构建知识库，还是通过和视觉、语音系统的联合建模获得？解决这一问题可能是下一大新闻的来源，也能将我们往 AI 推进一大步。</p>

<p>基于分布式语义假设的预训练同时受制于报道偏差 (Reporting Bias)[6]：不存在语料里的表达可能是真知识，而存在语料里面的表达也可能是假知识，更不用提普遍存在的模型偏见 (Bias) 了。我们不能因为一百个人说了&rdquo;世上存在独角兽&rdquo;就认为其为真，也不能因为只有一个人说了&rdquo;地球绕着太阳转&rdquo;便把它当做无益的噪声丢弃掉。</p>

<p>为了达到足够大的模型容量，我们真的需要这么大的计算量吗？已经有工作证明训练充分的 Transformer 里面存在很多重复冗余的模块 [6]。除了把网络加深加宽外，我们还有什么办法去增大模型容量的同时，保持一定的计算量？<br />
<br /><em>参考文献</em><br /><em>[1] Firth, J. R. (1957). Papers in linguistics 1934–1951. London: Oxford University Press.</em><br /><em>[2] Levy O, Goldberg Y. Neural word embedding as implicit matrix factorization[C]//Advances in neural information processing systems. 2014: 2177-2185.</em><br /><em>[3] Mahajan D, Girshick R, Ramanathan V, et al. Exploring the limits of weakly supervised pretraining[C]//Proceedings of the European Conference on Computer Vision (ECCV). 2018: 181-196.</em><br /><em>[4] Hestness J, Narang S, Ardalani N, et al. Deep learning scaling is predictable, empirically[J]. arXiv preprint arXiv:1712.00409, 2017.</em><br /><em>[5] Louwerse M M. Knowing the meaning of a word by the linguistic and perceptual company it keeps[J]. Topics in cognitive science, 2018, 10(3): 573-589.</em><br /><em>[6] Gordon J, Van Durme B. Reporting bias and knowledge acquisition[C]//Proceedings of the 2013 workshop on Automated knowledge base construction. ACM, 2013: 25-30.</em><br /><em>[7] Michel P, Levy O, Neubig G. Are Sixteen Heads Really Better than One?[J]. arXiv preprint arXiv:1905.10650, 2019.</em></p>

</div>


  <footer class="container">
  <div class="container navigation no-print">
  <h2>Navigation</h2>
  
  

    
    <a class="prev" href="https://7125messi.github.io/post/transformer%E6%8A%80%E6%9C%AF%E5%AE%9E%E6%88%98/" title="Transformer技术实战">
      Previous
    </a>
    

    
    <a class="next" href="https://7125messi.github.io/post/nlp%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%90%84%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%BB%BC%E8%BF%B0/" title="NLP深度学习的各类模型综述">
      Next
    </a>
    

  


</div>

  

</footer>

</article>
      <footer id="main-footer" class="container main_footer">
  

  <div class="container nav foot no-print">
  

  <a class="toplink" href="#">back to top</a>

</div>

  <div class="container credits">
  
<div class="container footline">
  
  code with <i class='fa fa-heart'></i>


</div>


  
<div class="container copyright">
  
  &copy; 2018 7125messi.


</div>


</div>

</footer>

    </main>
    


<script src="/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>



    
  </body>
</html>

